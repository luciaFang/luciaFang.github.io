<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!--<meta name=description content="This site was generated with Anima. www.animaapp.com"/>-->
    <!-- <link rel="shortcut icon" type=image/png href="https://animaproject.s3.amazonaws.com/home/favicon.png" /> -->
    <meta name="viewport" content="width=1497, maximum-scale=1.0" />
    <link rel="shortcut icon" type="image/png" href="https://animaproject.s3.amazonaws.com/home/favicon.png" />
    <meta name="og:type" content="website" />
    <meta name="twitter:card" content="photo" />
    <link rel="stylesheet" type="text/css" href="css/macbook-pro-14-11.css" />
    <link rel="stylesheet" type="text/css" href="css/styleguide.css" />
    <link rel="stylesheet" type="text/css" href="css/globals.css" />
  </head>
  <body style="margin: 0; background: #ffffff">
    <input type="hidden" id="anPageName" name="page" value="macbook-pro-14-11" />
    <div class="container-center-horizontal">
      <div class="macbook-pro-14-11 screen">
        <div class="frame-1">
          <a href="macbook-pro-14-5.html">
            <div class="div">
              <div class="div-1">
                <img
                  class="nyc_headshot_-_cropped_aoyjpg"
                  src="img/nyc-headshot---cropped-aoy-jpg-1@2x.png"
                  alt="nyc_headshot_-_cropped_AOY.jpg"
                />
              </div>
              <div class="div-2">
                <div class="place valign-text-middle sourcesanspro-normal-medium-red-violet-16px">Back</div>
              </div>
            </div></a
          >
          <div class="overlap-group3">
            <h1 class="title valign-text-middle">Sensing Projects</h1>
            <p class="x05-499-building-user valign-text-middle">05-499 Building User-Focused Sensing Systems</p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-col">
            <div class="divcomp-kxc4utlh">
              <div class="overlap-group5">
                <div class="step-counter-demo valign-text-middle inter-bold-mahogany-30px">
                  <span
                    ><span class="inter-bold-mahogany-30px">Step Counter (</span
                    ><a href="https://www.youtube.com/shorts/I-YGfLhJZt4" target="_blank"
                      ><span class="span1 inter-bold-mahogany-30px">Demo</span></a
                    ><span class="inter-bold-mahogany-30px">)</span>
                  </span>
                </div>
              </div>
            </div>
            <div class="overlap-group4">
              <p class="obtained-the-x-y-z valign-text-middle inter-normal-black-16px">
                Obtained the x, y, z coordinates using the accelerometer on the phone<br />In order to find the combined
                movement across the three dimensions, I computed the root mean square at each time point. <br />I
                applied a low pass filter in real-time since there could be accelerometer measurement jitters that
                oscillate at a much higher frequency than actual strides. <br />To perform a low pass filter in
                real-time, I resorted to the ‚ÄúOne Euro Filter‚Äù, of which, depending on the signal speed (differential
                displacement values), the filter adjusts its cutoff frequency for each new sample. <br />Although this
                prevents high frequency noise from being recorded, I could still have a jagged signal. I then opted to
                smooth the signal to understand the oscillatory direction of our steps (which would be later used to
                identify the strides of a person). In detail, I smoothed the signal by finding the median displacement
                every 7 samples. <br />Using the median values every 5 samples lowers the sample rate, and subsequently
                improves our signal-to-noise ratio. <br />The main reason I would like the displacement values to be
                more coarse is to be able to leverage the use of displacement directionality as the key identifier for
                peaks. In other words, peaks are identified when the adjacent displacement differences of the smoothed
                signal changes direction. Finally, to prevent rebound effects (deviated signal has to return to
                baseline), I implemented a 14 sample step counting time out between two peaks.
              </p>
            </div>
          </div>
          <img
            class="screenshot-2023-03-11-at-1158-1"
            src="img/screenshot-2023-03-11-at-11-58-1.png"
            alt="Screenshot 2023-03-11 at 11.58 1"
          />
        </div>
        <div class="flex-col-1 flex-col-7">
          <div class="divcomp-kyey590p"></div>
          <div class="flex-row-1">
            <div class="flex-col-2 flex-col-7">
              <div class="overlap-group-container">
                <div class="overlap-group7 inter-normal-cultured-pearl-16px">
                  <div class="square-blue">Square: Blue</div>
                  <img class="img_4423-3" src="img/img-4423-3@2x.png" alt="IMG_4423 3" />
                  <div class="circle-red">Circle: Red</div>
                </div>
                <div class="overlap-group8">
                  <div class="square-blue-1 inter-normal-cultured-pearl-16px">Square: Blue</div>
                </div>
              </div>
              <div class="overlap-group-container-1">
                <div class="overlap-group6">
                  <img class="img_4419" src="img/img-4419@2x.png" alt="IMG_4419" />
                  <div class="triangle-purple inter-normal-cultured-pearl-16px">Triangle: Purple</div>
                </div>
                <div class="overlap-group9">
                  <div class="line-green inter-normal-cultured-pearl-16px">Line: Green</div>
                </div>
              </div>
            </div>
            <div class="flex-col-3 flex-col-7">
              <div class="div-3">
                <p class="embedded-computing-with-particle-demo valign-text-middle inter-bold-mahogany-30px">
                  <span
                    ><span class="inter-bold-mahogany-30px">Embedded Computing with Particle (</span
                    ><a href="https://www.youtube.com/watch?v=4HFoks-_730" target="_blank"
                      ><span class="span1 inter-bold-mahogany-30px">Demo</span></a
                    ><span class="inter-bold-mahogany-30px">)</span>
                  </span>
                </p>
              </div>
              <div class="divcomp-kxc4riom">
                <p class="first-i-utilized-qw valign-text-middle inter-normal-black-16px">
                  First, I utilized QwiiC Accelerometer and library MMA8452Q to stream the x, y, z positions at 12Hz, or
                  12 samples per second. To compute displacement in each direction (x and y), I queued up 6 samples
                  (every 0.5s), and summed up the differences between samples. For simplicity, I opted to forgo z
                  dimensional change and just perform these gestures in a two dimensional plane. Once the displacements
                  were calculated in either dimension, I classified whether the direction of movement is in ‚Äúx‚Äù, ‚Äúy‚Äù, or
                  ‚Äúboth (diagonal)‚Äù direction during that 0.5s through: an x-line if x displacement is greater than
                  3-fold of y displacement; a y-line if vice versa; and a diagonal-line if both were moving greater than
                  a defined threshold. Second, I tallied these classified movements and designed a heuristic decoder
                  that identifies my gesture every 5 movements (since squares will require at least 4 lines). For line,
                  it is composed of at least 4 x-lines; for triangle, it is composed of at least 2 diagonal lines and 2
                  x-lines; for square it is composed of at least 2 x- and 2 y-lines; and for circle it is composed of at
                  least 4 diagonal lines. Finally, I flashed the LED the corresponding colors when a certain gesture is
                  identified: green for line, purple for triangle, blue for square, and red for circle.<br />While I can
                  serial print the identified gesture in the command line interface (CLI), per instruction, I also
                  implemented Particle publish (Particle.publish(‚Äúi_detect_square‚Äù)) to broadcast such an event that can
                  be received by any other device, or through ‚Äúparticle subscribe i_detect_square‚Äù in the CLI.<br />Last
                  part of the assignment required me to expand the gesture decoder and read out with ‚Äúparticle serial
                  monitor‚Äù in the CLI; therefore, I implemented gesture detection for alphabets ‚ÄúO‚Äù, ‚ÄúI‚Äù, and ‚ÄúX‚Äù. For
                  ‚ÄúO‚Äù, it reuses the heuristic for circle; for ‚ÄúI‚Äù, it uses a similar heuristic as line, but in the
                  vertical dimension, where more than 4 y-lines are detected every 5 classified movements; and for ‚ÄúX‚Äù,
                  it is composed of at least 2 diagonal lines connected with at least 2 y-lines.
                </p>
              </div>
            </div>
          </div>
          <div class="flex-col-4 flex-col-7">
            <div class="divcomp-kyey590p-1"></div>
            <div class="final-project-proposal valign-text-middle">Final Project Proposal</div>
            <div class="div-4">
              <p class="emotion-recognition-streamlit-web-cam valign-text-middle inter-bold-mahogany-30px">
                Emotion Recognition: Streamlit + WebCam
              </p>
            </div>
            <div class="div-5">
              <p class="recently-mental-hea valign-text-middle">
                Recently, mental health issues have been pervasive. Medical professionals find it difficult to parse
                their patient‚Äôs emotions after counseling sessions. Having a facial expression classifier could help
                provide invaluable feedback to the effectiveness of therapy.<br />I propose to use open source facial
                detection code and emotion dataset to build a real-time emotion classification to assist mental health
                professionals in providing more objective and evidence-based therapy to their patients and assisting in
                improving their emotional well-being.<br />The sensor would be a webcam from any computer. I will
                utilize google mediapipe python package for facial landmark detection alongside tensorflow convolutional
                neural network for emotional recognition.
              </p>
            </div>
            <div class="flex-row-2">
              <div class="divcomp-kxc4riom-1">
                <p class="existing-face-emotio valign-text-middle inter-bold-black-16px">
                  <span
                    ><span class="inter-bold-black-16px">Existing face emotion classifications<br /></span
                    ><span class="inter-normal-black-16px"
                      >Accuracy (60-70%)<br />I think it is due to variable background and face coverings. <br /></span
                    ><span class="inter-bold-black-16px">Therefore, my proposal <br /></span
                    ><span class="inter-normal-black-16px"
                      >Standardize facial images through extracting face patterns using an existing image recognition
                      model developed by google mediapipe to de-emphasis of non-important features (facial coverings/
                      skin tone/ hair).<br />Apply a neural network to match emotion to the subject from a webcam<br />Once
                      I identify the emotion (could be every 30 seconds, or shorter), I plan to queue up a playlist of
                      youtube videos to tailor to the emotion&nbsp;&nbsp;(music etc).</span
                    >
                  </span>
                </p>
              </div>
              <img class="sensing_project-2" src="img/sensing-project-2.png" alt="sensing_project 2" />
            </div>
            <div class="div-6">
              <div class="div-7">
                <div class="div-8">
                  <div class="div-9">
                    <img
                      class="nyc_headshot_-_cropped_aoyjpg-1"
                      src="img/nyc-headshot---cropped-aoy-jpg@2x.png"
                      alt="nyc_headshot_-_cropped_AOY.jpg"
                    />
                  </div>
                  <div class="div-10">
                    <div class="name valign-text-middle lato-bold-onyx-18px">Lucia Fang</div>
                    <a href="https://github.com/luciaFang/Resume_HCI/blob/main/lucia_ResumeHCI.pdf" target="_blank"
                      ><div class="resume valign-text-middle lato-normal-cape-cod-14px">Resume&nbsp;&nbsp;üëã</div>
                    </a>
                  </div>
                </div>
              </div>
              <div class="div-11">
                <p class="see-more-of-my-work valign-text-middle sourcesanspro-semi-bold-quick-silver-14px">
                  SEE MORE OF MY WORK:
                </p>
                <div class="div-12">
                  <div class="flex-col-5 flex-col-7">
                    <a href="macbook-pro-14-17.html">
                      <div class="div-13">
                        <div class="div-14">
                          <img
                            class="dl6-s-aik-iwp-ultfdcpng"
                            src="img/dl6saikiwpultfdc-png-5@2x.png"
                            alt="Dl6SAikIwpULTFDC.png"
                          />
                        </div>
                        <div class="div-15">
                          <div class="h4">
                            <div class="oh-lab valign-text-middle lato-normal-trout-16px">OH! Lab</div>
                          </div>
                        </div>
                      </div></a
                    >
                    <div class="div-16">
                      <div class="overlap-group">
                        <div class="div-17">
                          <img
                            class="m-mal-nog4-sn1p-z-nt-epng"
                            src="img/mmalnog4sn1pznte-png@2x.png"
                            alt="mMALNog4SN1pZNtE.png"
                          />
                        </div>
                        <a href="macbook-pro-14-8.html">
                          <div class="link">
                            <div class="h4-4">
                              <div class="rate-my-ta valign-text-middle lato-normal-trout-16px">Rate My TA</div>
                            </div>
                          </div></a
                        >
                      </div>
                    </div>
                  </div>
                  <div class="flex-col-6 flex-col-7">
                    <a href="macbook-pro-14-14.html">
                      <div class="link-1">
                        <div class="overlap-group">
                          <div class="div-18">
                            <img
                              class="m-mal-nog4-sn1p-z-nt-epng-3"
                              src="img/mmalnog4sn1pznte-png-2@2x.png"
                              alt="mMALNog4SN1pZNtE.png"
                            />
                          </div>
                          <div class="div-19">
                            <div class="h4-4">
                              <div class="sign-language-translation-app valign-text-middle lato-normal-trout-16px">
                                Sign Language Translation App
                              </div>
                            </div>
                          </div>
                        </div>
                      </div></a
                    ><a href="macbook-pro-14-14.html">
                      <div class="link-1">
                        <div class="overlap-group">
                          <div class="div-20">
                            <img
                              class="m-mal-nog4-sn1p-z-nt-epng-3"
                              src="img/mmalnog4sn1pznte-png-3@2x.png"
                              alt="mMALNog4SN1pZNtE.png"
                            />
                          </div>
                          <a href="macbook-pro-14-5.html" onclick="window.event.stopPropagation()">
                            <div class="link">
                              <div class="h4-4">
                                <div class="ads-bias-on-instagram valign-text-middle lato-normal-trout-16px">
                                  Ads bias on Instagram
                                </div>
                              </div>
                            </div></a
                          >
                        </div>
                      </div></a
                    >
                  </div>
                </div>
              </div>
            </div>
            <div class="div-21"></div>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
