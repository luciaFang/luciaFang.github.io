<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!--<meta name=description content="This site was generated with Anima. www.animaapp.com"/>-->
    <!-- <link rel="shortcut icon" type=image/png href="https://animaproject.s3.amazonaws.com/home/favicon.png" /> -->
    <meta name="viewport" content="width=1497, maximum-scale=1.0" />
    <link rel="shortcut icon" type="image/png" href="https://animaproject.s3.amazonaws.com/home/favicon.png" />
    <meta name="og:type" content="website" />
    <meta name="twitter:card" content="photo" />
    <link rel="stylesheet" type="text/css" href="css/macbook-pro-14-19.css" />
    <link rel="stylesheet" type="text/css" href="css/styleguide.css" />
    <link rel="stylesheet" type="text/css" href="css/globals.css" />
  </head>
  <body style="margin: 0; background: #ffffff">
    <input type="hidden" id="anPageName" name="page" value="macbook-pro-14-19" />
    <div class="container-center-horizontal">
      <div class="macbook-pro-14-19 screen">
        <div class="group-container">
          <div class="group-2337">
            <div class="flex-col flex">
              <div class="group-2330">
                <a href="index.html">
                  <div class="div">
                    <div class="div-1">
                      <img
                        class="nyc_headshot_-_cropped_aoyjpg"
                        src="img/rectangle-2@2x.png"
                        alt="nyc_headshot_-_cropped_AOY.jpg"
                      />
                    </div>
                    <div class="div-2">
                      <div class="place valign-text-middle sourcesanspro-normal-medium-red-violet-16px">Back</div>
                    </div>
                  </div></a
                >
                <div class="overlap-group3">
                  <div class="div-3">
                    <div class="div-4">
                      <div class="divw-node-eb91d102-9">
                        <div class="overlap-group-1">
                          <h1 class="title valign-text-middle">
                            <span
                              ><span class="span">Sign Language </span><span class="span1">Translation</span
                              ><span class="span"> App</span>
                            </span>
                          </h1>
                          <p class="undergraduate-independent-study-in-mcs valign-text-middle">
                            Undergraduate Independent Study in MCS
                          </p>
                        </div>
                        <div class="a">
                          <div class="design valign-text-middle montserrat-normal-white-16px">Design</div>
                        </div>
                      </div>
                    </div>
                  </div>
                  <div class="device-macbook-pro">
                    <div class="overlap-group2">
                      <div class="overlap-group-2">
                        <div class="dark-screen"></div>
                        <div class="macbook-pro">Macbook Pro</div>
                      </div>
                      <div class="bottom">
                        <div class="overlap-group1"><img class="groove" src="img/groove.svg" alt="Groove" /></div>
                        <img class="bottom-curve" src="img/bottom-curve.svg" alt="Bottom Curve" />
                      </div>
                      <img class="app-1" src="img/app-1.png" alt="app 1" />
                    </div>
                    <div class="shadow"></div>
                  </div>
                </div>
              </div>
              <p class="fall-2022-ux-design valign-text-middle">FALL 2022 | UX DESIGN</p>
            </div>
            <div class="flex-row flex">
              <div class="flex-col-1 flex-col-8">
                <div class="objective valign-text-middle montserrat-bold-black-20px">OBJECTIVE</div>
                <p class="one-of-the-biggest-c valign-text-middle">
                  One of the biggest challenges in sign language translation is the lack of technology supporting
                  translation between different regions. To address this issue, under the supervision of my mentor, we
                  have developed a no-code web interface for a state-of-the-art hand tracking algorithm called
                  Mediapipe, which can track hands in videos with high accuracy. To further enhance our approach, we
                  have developed a new method to track time points with corresponding 3D hand poses. Building on our
                  progress from last semester, I am currently collecting more American, Spanish, and Chinese sign
                  language videos. Our goal is to build a supervised Convolutional Neural Network that can read
                  finger-spelling for each language. To facilitate sign translation across languages, we will leverage
                  the Google Translate API, followed by text to image reconstruction to provide a more intuitive sign
                  language translation. Our project has the potential to make a significant impact in improving
                  accessibility and communication for the deaf and hard of hearing community.
                </p>
              </div>
              <div class="divw-node-_e-container">
                <div class="divw-node-_266e3334">
                  <div class="role valign-text-middle montserrat-bold-black-20px">ROLE</div>
                  <div class="ulw-node-d3438cca-24 montserrat-normal-dove-gray-16px">
                    <div class="ulw-node-d3438cca-24-item valign-text-middle">UX/UI Design</div>
                    <div class="ulw-node-d3438cca-24-item valign-text-middle">User Research</div>
                    <div class="web-development valign-text-middle">Web Development</div>
                  </div>
                </div>
                <div class="divw-node-_266e3334-1">
                  <div class="timeline valign-text-middle montserrat-bold-black-20px">TIMELINE</div>
                  <p class="name valign-text-middle montserrat-normal-dove-gray-16px">August 2022 - May 2023</p>
                </div>
              </div>
            </div>
            <div class="div-5">
              <p class="the-purpose-of-the-r valign-text-middle">
                The purpose of the research was to develop a system capable of recognizing American Sign language
                <br />(ASL) finger-spelling in real time. People who are deaf or hard of hearing use finger-spelling to
                <br />communicate, in which each letter of the alphabet is represented by a unique hand gesture.
                <br />In our pipeline, video input of a person‚Äôs finger-spelling is analyzed using machine learning
                algorithms, <br />and the corresponding letters are outputted in real-time, enabling people who use
                finger-spelling to<br />
                communicate with others who are unfamiliar with the gestures. Our pipeline can facilitate
                <br />communication and improve the lives of people who are deaf or hard of hearing by decoding
                <br />finger-spelling in real time.
              </p>
            </div>
            <p class="x3-d-pose-estimation-of-hand-for-asl valign-text-middle montserrat-bold-black-20px">
              3D POSE ESTIMATION OF HAND FOR ASL
            </p>
            <p class="our-research-utilize valign-text-middle">
              Our research utilized a video of a person finger spelling to extract 3D pose information through
              Mediapipe. Theextraction allowed us to determine which letters were being represented and how the hand
              pose changed over time.The plotted 3D coordinates of 24 out of the 26 letters as well as ‚Äùbackground‚Äù of
              the alphabet provide a visualrepresentation of the extracted data (Fig. 2a), which can be used to analyze
              and improve the finger-spelling de-coding algorithm‚Äôs accuracy. By using the plotted 3D coordinates as a
              ‚Äùreduced‚Äù set of features, we can develop afinger-spelling classifier for American Sign Language (ASL).
              This approach generalizes across different hand sizes,video resolutions, camera angles, and backgrounds.
              The classifier‚Äôs versatility enables accurate decoding of finger-spelling in various situations, making it
              a more useful tool
            </p>
            <div class="overlap-group7">
              <p class="figure-1-3-d-hand-po valign-text-middle">
                Figure 1: 3D hand pose extracted from an example video of ASL finger-spelling. (A) Example screenshot of
                a video frame <br />signing the letter ‚ÄùF‚Äù. (B) Developed a no-code web browser to automatically detect
                one or more hand skeletons using <br />Mediapipe. (C) The extracted 3D pose every 2 seconds, with the
                correct alphabets titled.
              </p>
              <img
                class="screenshot-2023-02-27-at-1241-2"
                src="img/screenshot-2023-02-27-at-12-41-2.png"
                alt="Screenshot 2023-02-27 at 12.41 2"
              />
            </div>
            <div class="results valign-text-middle montserrat-bold-black-20px">RESULTS</div>
            <div class="overlap-group4">
              <div class="group-2331">
                <div class="development-of-an-user-interface valign-text-middle">Development of an user-interface</div>
                <p class="mediapipe-is-a-machi valign-text-middle">
                  <span
                    ><span class="montserrat-bold-victoria-11px">Mediapipe</span
                    ><span class="montserrat-normal-black-11px"> is a machine learning framework that can </span
                    ><span class="montserrat-bold-victoria-11px">decode hand skeletons in real-time </span
                    ><span class="montserrat-normal-black-11px"
                      >which is an useful tool to decode the meaning of the sign language. In order to make it easier to
                      use Mediapipe for this purpose, we developed a user interface that simplifies the process of
                      decoding sign language from video input, making it easier to use. An interactive web-based
                      application was designed to </span
                    ><span class="montserrat-bold-victoria-11px">allow the user upload a sign video</span
                    ><span class="montserrat-normal-black-11px">, and then </span
                    ><span class="montserrat-bold-victoria-11px"
                      >watch the replay with predicted hand skeleton superimposed</span
                    ><span class="montserrat-normal-black-11px"
                      >. <br /><br />As a result, the user will be able to see exactly </span
                    ><span class="montserrat-bold-victoria-11px">how the hand pose is being interpreted</span
                    ><span class="montserrat-normal-black-11px"> by the system and can </span
                    ><span class="montserrat-bold-victoria-11px">adjust it as necessary</span
                    ><span class="montserrat-normal-black-11px">
                      to improve the accuracy of the decoded sign language that is being produced. Furthermore, the user
                      interface </span
                    ><span class="montserrat-bold-victoria-11px"
                      >includes tools for post-processing the decoded hand skeleton data</span
                    ><span class="montserrat-normal-black-11px"
                      >, such as creating a 2D convolution neural network that </span
                    ><span class="montserrat-bold-victoria-11px">maps these hand pose images to signed alphabet</span
                    ><span class="montserrat-normal-black-11px"
                      >. Overall, our user-interface makes it easy for anyone to use Mediapipe to decode signlanguage in
                      real-time.</span
                    >
                  </span>
                </p>
              </div>
              <div class="flex-col-2 flex-col-8">
                <img class="fig1_page-0001-1" src="img/fig1-page-0001-1@2x.png" alt="fig1_page-0001 1" />
                <p class="figure1-no-code-gui valign-text-middle">
                  FIGURE1: NO-CODE GUI FOR SIGN LANGUAGE TRAINING. (A) ALPHABET ‚ÄùC‚Äù SIGNED VIEWED FROM TWO DIFFERENT
                  AZIMUTHS. (B) ALPHABET ‚ÄùG‚Äù SIGNED VIEWED FROM TWO DIFFERENT ELEVATIONS. (C) FIRST PAGE OF APP,
                  EXTRACTING 3D HAND POSE FROM VIDEOS. (D)SECOND PAGE OF APP, TRAINING A CONVOLUTION NEURAL NETWORK TO
                  READ SIGN FROM POSE.
                </p>
              </div>
            </div>
            <div class="overlap-group-3">
              <div class="group-2331-1">
                <div class="flex-col-3 flex-col-8">
                  <p class="convolution-neural-n valign-text-middle">
                    Convolution Neural Network training and prediction
                  </p>
                  <p class="with-3-d-pose-and-it valign-text-middle">
                    <span
                      ><span class="montserrat-normal-black-11px"
                        >With 3D pose and it‚Äôs corresponding alphabet, we opted to train a 2D convolution neural
                        network. First, we </span
                      ><span class="span1-1">projected these 3D hand pose (Fig. 2a) onto 2D</span
                      ><span class="montserrat-normal-black-11px"> and down-sample the </span
                      ><span class="montserrat-bold-purple-11px">high resolution images to 128x128 pixels</span
                      ><span class="montserrat-normal-black-11px">
                        to be able to generalize hand shape and subtle angle differences between signers.
                        <br /><br />Across two videos, we split into </span
                      ><span class="montserrat-bold-purple-11px">70%train and 30% test</span
                      ><span class="montserrat-normal-black-11px"
                        >. Upon 20 training epochs, the validation accuracy plateaued and reached </span
                      ><span class="montserrat-bold-purple-11px">90%</span
                      ><span class="montserrat-normal-black-11px">
                        (Fig. 2b). Next, we sought to investigate the mistakes from each alphabet and background (BG)
                        and found that, </span
                      ><span class="montserrat-bold-purple-11px"
                        >as expected, stationary signs without occlusion of fingers works well; whereas moving signs
                        such as ‚ÄùJ‚Äù, and ‚ÄùZ‚Äù, along with occluded sign like ‚ÄùO‚Äù were often times confused with
                        background (Fig. 2c).</span
                      >
                    </span>
                  </p>
                </div>
                <img class="fig2_page-0001-1" src="img/fig2-page-0001-1@2x.png" alt="fig2_page-0001 1" />
              </div>
              <p class="figure-2-alphabets valign-text-middle">
                FIGURE 2: ALPHABETS SUCCESSFULLY DECODED FROM HAND POSE. (A) EXTRACTED 3D HAND POSE FOR MOST ALPHABETS,
                WITH THE COR-RECT ALPHABETS TITLED. (B) TRAINING AND VALIDATION PERFORMANCE OF 2D CONVOLUTION NEURAL
                NETWORK FITTED ON POSE AND CORRE-SPONDING SIGN. (C) CONFUSION MATRIX OF PREDICTED SIGN (ROWS), AND THE
                ACTUAL SIGN (COLUMNS)
              </p>
            </div>
            <div class="flex-row-1">
              <div class="flex-col-4 flex-col-8">
                <div class="setbacks valign-text-middle montserrat-bold-white-20px">SETBACKS</div>
                <p class="mediapipe-is-a-machi-1 valign-text-middle">
                  <span
                    ><span class="montserrat-normal-soapstone-20px"
                      >Mediapipe is a machine learning framework designed to predict hand poses in videos using prebuilt
                      supervised neural network classifiers. It allows for predicting the hand pose in every frame of a
                      video, and the predicted pose can be overlaid on the input video frame as a reference. However,
                      the only output provided to the end-user is real-time prediction of the hand pose, with limited
                      support for post-hoc analysis of the data. As a result, </span
                    ><span class="span1-2"
                      >in experienced users may find it challenging to annotate, quantify, and classify various signs in
                      a video, particularly in continuous streams. </span
                    ><span class="montserrat-normal-soapstone-20px"
                      >Nonetheless, it is possible to work around these limitations</span
                    ><span class="span3">&nbsp;</span
                    ><span class="montserrat-bold-shilo-20px"
                      >by writing the hand pose and the corresponding frame number to a writable data file, enabling the
                      user to revisit specific time points of a video for further analysis</span
                    ><span class="montserrat-normal-soapstone-20px"
                      >. While Mediapipe‚Äôs lack of support for post-hoc analysis is a limitation, it remains a useful
                      tool for processing and visualizing an entire video, provided users are willing to use
                      workarounds.3</span
                    >
                  </span>
                </p>
              </div>
              <div class="flex-col-5 flex-col-8">
                <div class="conclusion valign-text-middle montserrat-bold-white-20px">CONCLUSION</div>
                <p class="we-developed-a-user valign-text-middle">
                  <span
                    ><span class="montserrat-normal-white-20px">We developed a </span
                    ><span class="montserrat-bold-shilo-20px"
                      >user-friendly, front-end web application that incorporates Mediapipe‚Äôs real-time hand pose
                      prediction with post-hoc quantification and visualization scripts to increase the usability of
                      cutting-edge technology</span
                    ><span class="montserrat-normal-white-20px"
                      >. Specifically, we focused on ASL finger-spelling decoding and demonstrated diverse 3D hand poses
                      across all alpha-bets. </span
                    ><span class="montserrat-bold-shilo-20px"
                      >With this application, users can upload a video of themselves signing in ASL, and the algorithm
                      will deter-mine the hand position at each frame.</span
                    ><span class="montserrat-bold-white-20px">&nbsp;</span
                    ><span class="montserrat-normal-white-20px"
                      >The retrieved hand pose information can then be compared and contrasted with one another.
                      Additionally, we leveraged the 3D pose generated from Mediapipe to enable a convolution neural
                      network to learn the signed alphabet from the hand pose images. The network achieved a validation
                      accuracy of </span
                    ><span class="montserrat-bold-shilo-20px">90%</span
                    ><span class="montserrat-normal-white-20px"
                      >. However, we noted that the network fails when the alphabet sign is non-stationary, or the hand
                      isn‚Äôt fully visible. Ultimately, by combining Mediapipe‚Äôs hand pose prediction with another layer
                      of 2D convolution neural network, we created a powerful tool for</span
                    ><span class="montserrat-bold-shilo-20px">
                      improving ASL finger-spelling classification, benefiting the deaf and hardof hearing
                      community</span
                    ><span class="montserrat-normal-white-20px">.</span>
                  </span>
                </p>
              </div>
            </div>
            <div class="prospect-for-the-future valign-text-middle montserrat-bold-black-20px">
              PROSPECT FOR THE FUTURE
            </div>
            <div class="overlap-group6">
              <p class="the-next-step-is-to valign-text-middle montserrat-normal-black-11px">
                <span
                  ><span class="montserrat-normal-black-11px">The next step is to </span
                  ><span class="span-2"
                    >develop a real-time sign language translation app that has the potential to revolutionize
                    communication for the deaf community on a global scale</span
                  ><span class="montserrat-normal-black-11px"
                    >. What we envision is an improved version of the app that utilize a video stream that captures an
                    image every half a second, which will then be fed into Mediapipe to identify 3D hand pose. This
                    information will be passed through our trained convolution neural network, which will output the
                    corresponding English alphabet. By stacking these alphabets and segmenting them with 1-2 seconds of
                    background classification, we will construct English words and formulate a sentence. Once the
                    sentence is complete, the app will translate the text into the language of the user&#39;s choice. To
                    complete the communication loop, we will add text-to-speech functionality. </span
                  ><span class="span-2"
                    >By integrating sign language decoding, text translation, and text-to-speech, our app has the
                    potential to facilitate seamless communication between the deaf and non-deaf populations, regardless
                    of language barriers.</span
                  >
                </span>
              </p>
            </div>
            <div class="div-6">
              <div class="div-7">
                <div class="div-8">
                  <div class="div-9">
                    <img
                      class="nyc_headshot_-_cropped_aoyjpg-1"
                      src="img/nyc-headshot---cropped-aoy-jpg-7@2x.png"
                      alt="nyc_headshot_-_cropped_AOY.jpg"
                    />
                  </div>
                  <div class="div-10">
                    <div class="name-1 valign-text-middle lato-bold-onyx-18px">Lucia Fang</div>
                    <a href="https://github.com/luciaFang/Resume_HCI/blob/main/lucia_ResumeHCI.pdf" target="_blank"
                      ><div class="resume valign-text-middle lato-normal-cape-cod-14px">Resume&nbsp;&nbsp;üëã</div>
                    </a>
                  </div>
                </div>
              </div>
              <div class="div-11">
                <p class="see-more-of-my-work valign-text-middle sourcesanspro-semi-bold-quick-silver-14px">
                  SEE MORE OF MY WORK:
                </p>
                <div class="div-12">
                  <div class="flex-col-6 flex-col-8">
                    <a href="macbook-pro-14-20.html">
                      <div class="link">
                        <div class="overlap-group2-1">
                          <div class="mac-book-pro-13">
                            <div class="screen-body">
                              <div class="camera">
                                <div class="ellipse-container ellipse">
                                  <div class="ellipse-3 ellipse"></div>
                                  <div class="ellipse-2 ellipse"></div>
                                </div>
                              </div>
                              <div class="display-paste-your-img">
                                <div class="overlap-group-4">
                                  <img
                                    class="screenshot-2023-05-07-at-1058-1"
                                    src="img/screenshot-2023-05-07-at-10-58-1@2x.png"
                                    alt="Screenshot 2023-05-07 at 10.58 1"
                                  />
                                </div>
                              </div>
                              <img
                                class="macbook-pro-13-sign"
                                src="img/macbook-pro-13-sign@2x.png"
                                alt="Macbook Pro 13 sign"
                              />
                            </div>
                            <img class="body" src="img/body@2x.png" alt="Body" />
                          </div>
                        </div>
                        <div class="div-13">
                          <div class="h4">
                            <div class="emo-sense valign-text-middle lato-normal-trout-16px">EmoSense</div>
                          </div>
                        </div>
                      </div></a
                    >
                    <div class="div-14">
                      <div class="overlap-group">
                        <div class="div-15">
                          <img
                            class="m-mal-nog4-sn1p-z-nt-epng"
                            src="img/mmalnog4sn1pznte-png-11@2x.png"
                            alt="mMALNog4SN1pZNtE.png"
                          />
                        </div>
                        <a href="macbook-pro-14-8.html">
                          <div class="div-16">
                            <div class="h4-1 h4-4">
                              <div class="rate-my-ta valign-text-middle lato-normal-trout-16px">Rate My TA</div>
                            </div>
                          </div></a
                        >
                      </div>
                    </div>
                  </div>
                  <div class="flex-col-7 flex-col-8">
                    <a href="macbook-pro-14-17.html">
                      <div class="link">
                        <div class="div-17">
                          <img
                            class="dl6-s-aik-iwp-ultfdcpng"
                            src="img/dl6saikiwpultfdc-png@2x.png"
                            alt="Dl6SAikIwpULTFDC.png"
                          />
                        </div>
                        <div class="div-18">
                          <div class="h4-4">
                            <div class="oh-lab valign-text-middle lato-normal-trout-16px">OH! Lab</div>
                          </div>
                        </div>
                      </div></a
                    ><a href="macbook-pro-14-21.html">
                      <div class="div-19">
                        <div class="overlap-group">
                          <div class="div-20">
                            <img
                              class="m-mal-nog4-sn1p-z-nt-epng-1"
                              src="img/mmalnog4sn1pznte-png@2x.png"
                              alt="mMALNog4SN1pZNtE.png"
                            />
                          </div>
                          <div class="div-21">
                            <div class="h4-3 h4-4">
                              <div class="ads-bias-on-instagram valign-text-middle lato-normal-trout-16px">
                                Ads bias on Instagram
                              </div>
                            </div>
                          </div>
                        </div>
                      </div></a
                    >
                  </div>
                </div>
              </div>
            </div>
            <div class="div-22"></div>
          </div>
          <div class="group-2294">
            <div class="div-23">
              <img
                class="nyc_headshot_-_cropped_aoyjpg-2"
                src="img/nyc-headshot---cropped-aoy-jpg@2x.png"
                alt="nyc_headshot_-_cropped_AOY.jpg"
              />
            </div>
            <a href="index.html">
              <div class="div-24">
                <div class="div-25">
                  <div class="place valign-text-middle sourcesanspro-normal-medium-red-violet-16px">Back</div>
                </div>
              </div></a
            >
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
